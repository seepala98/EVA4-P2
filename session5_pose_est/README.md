# Monocular Human Pose Estimation AND ONNX Models

## link to pose estimation : https://deeplearnjourney.s3.ap-south-1.amazonaws.com/face_align/index.html

## Assignment :

1. You are implementing "[Simple Baseline for HPE and tracking](https://github.com/Microsoft/human-pose-estimation.pytorch)". [Read the paper](https://arxiv.org/pdf/1804.06208.pdf) and write a detailed readme file describing the model architecture as well as the JointsMSELoss class.
2. Download the smallest [model](https://onedrive.live.com/?authkey=%21AFkTgCsr3CT9%2D%5FA&id=56B9F9C97F261712%2110709&cid=56B9F9C97F261712) and upload to Lambda for HPE detection
3. Make sure to draw the points on the image, as well as connect the joints in the right fashion.



## Results:

input image : ![putin_walk](https://github.com/seepala98/EVA4-P2/blob/master/session5_pose_est/images/puting_walk.jpg)

output image with pose : ![putin_pose](https://github.com/seepala98/EVA4-P2/blob/master/session5_pose_est/images/putin_pose.jpeg)

